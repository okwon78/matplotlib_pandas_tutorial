{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Math Modules\n",
    "\n",
    "tf.InteractiveSession을 사용해서 직접 값을 확인하도록 하겠다.   \n",
    "InteractiveSession을 사용한 후에는 close를 통해서 닫아줘야 한다.   \n",
    "필요에 따라서 사용하기 바란다.  \n",
    "x.eval()은 sess.run(x)와 동일하다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 6]\n",
      "[3 6]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "    \n",
    "# 실행의 간편함과 코드의 간결함을 위해서 InteractiveSession을 사용하도록 하겠다.\n",
    "interactiveSession = tf.InteractiveSession()\n",
    "\n",
    "x = tf.constant([3,6])\n",
    "\n",
    "print(x.eval())\n",
    "\n",
    "# is eqaul to\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactiveSession.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DType 주의 사항\n",
    "\n",
    "* 텐서플로우의 데이터 타입은 Numpy와 동일하다.\n",
    "* Python 타입이 타입 추론에 의해서 텐서플로우 타입으로 변경되지만, Python 타입은 사용하지 않는 것이 좋다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Baisc Operations\n",
    "\n",
    "* tf.add\n",
    "* tf.add_n\n",
    "* tf.multiply\n",
    "* tf.matmul\n",
    "* tf.div\n",
    "* tf.mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 8]\n",
      "[ 7 10]\n",
      "[ 6 12]\n",
      "[[ 6  6]\n",
      " [12 12]]\n",
      "[1 3]\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([3,6])\n",
    "y = tf.constant([2,2])\n",
    "\n",
    "print (tf.add(x, y).eval())\n",
    "print (tf.add_n([x, y, y]).eval())\n",
    "print (tf.multiply(x, y).eval())\n",
    "\n",
    "print (tf.matmul(tf.reshape(x, shape=(1,2)), tf.reshape(y, shape=(1,2)), transpose_a=True).eval())\n",
    "\n",
    "print (tf.div(x, y).eval())\n",
    "print (tf.mod(x, y).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Reduction\n",
    "\n",
    "리스트를 받아서 axis를 기준으로 평균을 반환\n",
    "\n",
    "```python\n",
    "tf.reduce_mean(\n",
    "    input_tensor,\n",
    "    axis=None,\n",
    "    keepdims=None,\n",
    "    name=None,\n",
    "    reduction_indices=None,\n",
    "    keep_dims=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5\n",
      "[1.5 1.5]\n",
      "[1. 2.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1., 1.], [2., 2.]])\n",
    "\n",
    "print(tf.reduce_mean(x).eval())\n",
    "print(tf.reduce_mean(x, axis=0).eval())\n",
    "print(tf.reduce_mean(x, axis=1).eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Sequence Comparison and Indexing\n",
    "해당 range에서 가장 큰 index를 반환 한다.\n",
    "\n",
    "```python\n",
    "tf.argmax(\n",
    "    input,\n",
    "    axis=None,\n",
    "    name=None,\n",
    "    dimension=None,\n",
    "    output_type=tf.int64\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:  [2 3 3]\n",
      "yhat:  [2 3 3]\n",
      "correct_preds:  [ True  True  True]\n",
      "accuracy:  3.0\n"
     ]
    }
   ],
   "source": [
    "y = tf.constant([[0,0,1,0], [0,0,0,1], [0,0,0,1]]) # one hot encoding\n",
    "yhat = tf.constant([[0.3,0.0,0.7,0.5], [0.4,0.2,0.1,0.6], [0.0,0.2,0.1,0.4]]) # predictions\n",
    "\n",
    "y_index = tf.argmax(y, axis=1)\n",
    "yhat_index = tf.argmax(yhat, axis=1)\n",
    "\n",
    "print('y: ', y_index.eval())\n",
    "print('yhat: ', yhat_index.eval())\n",
    "\n",
    "correct_preds = tf.equal(y_index, yhat_index)\n",
    "\n",
    "print('correct_preds: ', correct_preds.eval())\n",
    "\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_preds, dtype=tf.float32))\n",
    "\n",
    "print('accuracy: ', accuracy.eval())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Random\n",
    "\n",
    "tensorflow는 여러 분산으로 부터 랜덤 tensor를 생성하는 라이브러리를 제공한다.  \n",
    "자주 사용하는 함수는 다음과 같으니 익혀두는 것이 좋다.\n",
    "\n",
    "* tf.random_normal\n",
    "* tf.truncated_noraml\n",
    "* tf.random_uniform\n",
    "* tf.random_shuffle\n",
    "* tf.random_crop\n",
    "* tf.multinomial\n",
    "* tf.random_gamma\n",
    "\n",
    "랜덤 값을 재 생성하기 위해서는 seed값을 지정해야 한다.\n",
    "다음 매소드를 사용해 그래프 레벨의 seed를 지정할 수 있다.\n",
    "\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "조금 상세한 설명이 필요하지만 아주 간단히 설명하면 그래프 seed는 전체 seed로 사용되고 개발 매소드 seed는 개별로 사용된다.  \n",
    "랜덤 seed관련해서는 [링크](https://www.tensorflow.org/api_docs/python/tf/set_random_seed) 참고하기 바란다.\n",
    "\n",
    "\n",
    "대표적으로 많이 사용되는 truncated_normal를 살펴보겠다.\n",
    "truncated_normal은 random_normal과 동일하게 정규 분포를 따르는 랜덤 값을 반환 한다.   \n",
    "두드러지는 특징은 딥러닝 초기화에 사용할 경우, 표준 편차 2가 넘는 값을 버리기 때문에 truncated_normal가 더 좋은 성능을 보인다.\n",
    "\n",
    "```python\n",
    "tf.truncated_normal(\n",
    "    shape,\n",
    "    mean=0.0,\n",
    "    stddev=1.0,\n",
    "    dtype=tf.float32,\n",
    "    seed=None,\n",
    "    name=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.489018  , -0.09126794,  0.84315634],\n",
       "       [ 0.24372363,  1.4334596 ,  0.27243507]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.set_random_seed(0)\n",
    "norm = tf.truncated_normal(shape=(2, 3), mean=1, stddev=1)\n",
    "norm.eval()\n",
    "\n",
    "# 그래프 seed를 0으로 지정했기 때문에 항상 첫번째 값은 항상 다음과 같다.\n",
    "# [[-0.40955448,  0.46331722,  0.43476212],[ 1.5262461 ,  0.82560146,  1.2242969 ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 시퀀스의 인덱스를 랜덤하게 변경한다.  \n",
    "이미지의 시퀀스를 변경할 때 유용하게 사용할 수 있다.\n",
    "\n",
    "```python\n",
    "tf.random_shuffle(\n",
    "    value,\n",
    "    seed=None,\n",
    "    name=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant([[1, 2], [3, 4], [5, 6]])\n",
    "shuff = tf.random_shuffle(c)\n",
    "shuff.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Cross entropy\n",
    "\n",
    "* Binary classification\n",
    "\\\\[ -{(y\\log(p) + (1 - y)\\log(1 - p))} \\\\]\n",
    "\n",
    "```python\n",
    "tf.losses.sigmoid_cross_entropy(\n",
    "    multi_class_labels,\n",
    "    logits,\n",
    "    weights=1.0,\n",
    "    label_smoothing=0,\n",
    "    scope=None,\n",
    "    loss_collection=tf.GraphKeys.LOSSES,\n",
    "    reduction=Reduction.SUM_BY_NONZERO_WEIGHTS\n",
    ")\n",
    "```\n",
    "\n",
    "* Multiclass classification\n",
    "\n",
    "\\\\[ -\\sum_{c=1}^My_{o,c}\\log(p_{o,c}) \\\\]\n",
    "\n",
    "```python\n",
    "tf.nn.softmax_cross_entropy_with_logits(\n",
    "    _sentinel=None,\n",
    "    labels=None,\n",
    "    logits=None,\n",
    "    dim=-1,\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00134092 0.00134092 0.00589738]\n",
      "0.0028597414\n"
     ]
    }
   ],
   "source": [
    "# batch size을 3으로 가정한다.\n",
    "# logits은 sigmoid의 입력 값이다. [0~1] 사이 값이 아니다.\n",
    "logits = tf.constant([[-4,-4,-4,4,-4], [-4,-4,-4,-4,4], [-5,-2,-1,-1,5]], dtype=tf.float32)\n",
    "labels = tf.constant([[0,0,0,1,0], [0,0,0,0,1], [0,0,0,0,1]])\n",
    "\n",
    "# 5개에 대한 클래스에 모든 에러를 더한다. \n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels, name='loss')\n",
    "print(entropy.eval())\n",
    "\n",
    "# entropy / class 갯수 = 평균 entropy (loss)\n",
    "loss = tf.reduce_mean(entropy)\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Noise-contrastive estimation \n",
    "\n",
    "상세한 내용은 [링크](http://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf)를 참고하기 바란다.\n",
    "\n",
    "```python\n",
    "tf.nn.nce_loss(\n",
    "    weights,\n",
    "    biases,\n",
    "    labels,\n",
    "    inputs,\n",
    "    num_sampled,\n",
    "    num_classes,\n",
    "    num_true=1,\n",
    "    sampled_values=None,\n",
    "    remove_accidental_hits=False,\n",
    "    partition_strategy='mod',\n",
    "    name='nce_loss'\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
