{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Math Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 실행의 간편함과 코드의 간결함을 위해서 InteractiveSession을 사용하도록 하겠다.\n",
    "tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reduction\n",
    "\n",
    "리스트를 받아서 axis를 기준으로 평균을 반환\n",
    "\n",
    "```\n",
    "tf.reduce_mean(\n",
    "    input_tensor,\n",
    "    axis=None,\n",
    "    keepdims=None,\n",
    "    name=None,\n",
    "    reduction_indices=None,\n",
    "    keep_dims=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[1., 1.], [2., 2.]])\n",
    "\n",
    "a = tf.reduce_mean(x)\n",
    "print(a.eval())\n",
    "\n",
    "b = tf.reduce_mean(x, axis=0)\n",
    "print(b.eval())\n",
    "\n",
    "c = tf.reduce_mean(x, axis=1)\n",
    "print(c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sequence Comparison and Indexing\n",
    "해당 range에서 가장 큰 index를 반환 한다.\n",
    "\n",
    "```\n",
    "tf.argmax(\n",
    "    input,\n",
    "    axis=None,\n",
    "    name=None,\n",
    "    dimension=None,\n",
    "    output_type=tf.int64\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.constant([[0,0,1,0], [0,0,0,1], [0,0,0,1]]) # one hot encoding\n",
    "yhat = tf.constant([[0.3,0.0,0.7,0.5], [0.4,0.2,0.1,0.6], [0.0,0.2,0.1,0.4]]) # predictions\n",
    "\n",
    "y_index = tf.argmax(y, 1)\n",
    "yhat_index = tf.argmax(yhat, 1)\n",
    "\n",
    "print('y: ', y_index.eval())\n",
    "print('yhat: ', yhat_index.eval())\n",
    "\n",
    "correct_preds = tf.equal(y_index, yhat_index)\n",
    "\n",
    "print('correct_preds: ', correct_preds.eval())\n",
    "\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "\n",
    "print('accuracy: ', accuracy.eval())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cross entropy\n",
    "\n",
    "* Binary classification\n",
    "\\\\[ -{(y\\log(p) + (1 - y)\\log(1 - p))} \\\\]\n",
    "\n",
    "```python\n",
    "tf.losses.sigmoid_cross_entropy(\n",
    "    multi_class_labels,\n",
    "    logits,\n",
    "    weights=1.0,\n",
    "    label_smoothing=0,\n",
    "    scope=None,\n",
    "    loss_collection=tf.GraphKeys.LOSSES,\n",
    "    reduction=Reduction.SUM_BY_NONZERO_WEIGHTS\n",
    ")\n",
    "```\n",
    "\n",
    "* Multiclass classification\n",
    "\n",
    "\\\\[ -\\sum_{c=1}^My_{o,c}\\log(p_{o,c}) \\\\]\n",
    "\n",
    "```python\n",
    "tf.nn.softmax_cross_entropy_with_logits(\n",
    "    _sentinel=None,\n",
    "    labels=None,\n",
    "    logits=None,\n",
    "    dim=-1,\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size을 3으로 가정한다.\n",
    "# logits은 sigmoid의 입력 값이다. [0~1] 사이 값이 아니다.\n",
    "logits = tf.constant([[-4,-4,-4,4,-4], [-4,-4,-4,-4,4], [-5,-2,-1,-1,5]], dtype=tf.float32)\n",
    "labels = tf.constant([[0,0,0,1,0], [0,0,0,0,1], [0,0,0,0,1]])\n",
    "\n",
    "# 5개에 대한 클래스에 모든 에러를 더한다. \n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels, name='loss')\n",
    "print(entropy.eval())\n",
    "\n",
    "# entropy / class 갯수 = 평균 entropy (loss)\n",
    "loss = tf.reduce_mean(entropy)\n",
    "print(loss.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Noise-contrastive estimation \n",
    "\n",
    "상세한 내용은 [링크](http://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf)를 참고하기 바란다.\n",
    "\n",
    "```python\n",
    "tf.nn.nce_loss(\n",
    "    weights,\n",
    "    biases,\n",
    "    labels,\n",
    "    inputs,\n",
    "    num_sampled,\n",
    "    num_classes,\n",
    "    num_true=1,\n",
    "    sampled_values=None,\n",
    "    remove_accidental_hits=False,\n",
    "    partition_strategy='mod',\n",
    "    name='nce_loss'\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
