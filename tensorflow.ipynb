{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 예제로 간단하게 두 값을 더하는 그래프를 생성해서 tensorboard를 통해 살펴보기로 하자.  \n",
    "\n",
    ">앞으로 자주 출현하는 tf.reset_default_graph() 함수는  \n",
    "각 예제가 default graph에서 구동되기 때문에 각 예제의 충돌을 막기 위해서 초기화하는 함수이다.\n",
    "\n",
    "가장 먼저 다음과 같이 TF_CPP_MIN_LOG_LEVEL을 사용하여 로그 레벨을 지정하였다.\n",
    "\n",
    "```python\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "```\n",
    "각 레벨은 다음과 같다.\n",
    "\n",
    "* 0 = all messages are logged (default behavior)\n",
    "* 1 = INFO messages are not printed\n",
    "* 2 = INFO and WARNING messages are not printed\n",
    "* 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "    \n",
    "다음으로 tf.device를 지정해서 해당 그래프가 cpu에서 구동되도록 하였으며  \n",
    "로그 저장 위치를 tf.summary.FileWriter의 파라미터로 ./log로 지정하였다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 이름의 variable을 그래프에 추가할 수 없기 때문에 그래프를 리셋해줘야 한다.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 로그 레벨 지정\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "with tf.device('/cpu'):\n",
    "    a = tf.constant(3.0, dtype=tf.float32)\n",
    "    b = tf.constant(4.0)\n",
    "    total = a + b\n",
    "\n",
    "# tensorboard를 위해 그래프 추가\n",
    "# 그래프가 완성된 뒤 추가 되어야 한다.\n",
    "writer = tf.summary.FileWriter('./log', tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run({'ab':(a, b), 'total':total}), '\\n')   \n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Tensorboard\n",
    "\n",
    "tensorflow의 실행을 살펴보기 위해 tensorboard를 사용해 볼 수 있다.\n",
    "\n",
    "tensorboard의 실행 방법은 다음과 같다.  \n",
    "포트를 특별히 지정하지 않으면, 디폴트 포트로 6006이 사용된다.  \n",
    "\n",
    "\n",
    "```bash\n",
    "$ tensorboard --logdir=<path> --port=6006\n",
    "```\n",
    "\n",
    "위 예제 실행은 다음과 같다.\n",
    "\n",
    "```bash\n",
    "$ tensorboard --logdir=./log --port=6006\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 그래프의 동작 방식을 이해하기 위한 예제이다.  \n",
    "그래프가 3번 실행 된다.  \n",
    "마지막 실행에서 out1, out2가 동일한 vec값을 사용했다는 점을 확인하기 바란다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#변수 3개 반환\n",
    "vec = tf.random_uniform(shape=(3,))\n",
    "out1 = vec + 1\n",
    "out2 = vec + 2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('vec: {}'.format(sess.run(vec)))\n",
    "    print('vec: {}'.format(sess.run(vec)))\n",
    "    # out1, out2가 동일한 vec을 사용했다\n",
    "    print('out: {}'.format(sess.run((out1, out2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프에 임의의 상수값을 지정하여 추가할 수 있다.\n",
    "\n",
    "```python\n",
    "tf.constant(\n",
    "    value,\n",
    "    dtype=None,\n",
    "    shape=None,\n",
    "    name='Const',\n",
    "    verify_shape=False\n",
    ")\n",
    "```\n",
    "\n",
    "* 지정된 상수는 그래프와 함께 저장된다.  \n",
    "* 다음과 같이 값을 지정해서 텐서를 생성할 수 있다.\n",
    "* name을 지정하면 tensorboard에서 그래프에 해당 이름이 표시된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# constant of 0d tensor (scalar)\n",
    "a = tf.constant(2, name='scalar')\n",
    "print('a.shape: ', a.shape)\n",
    "\n",
    "# constant of 1d tensor (vector)\n",
    "b = tf.constant([2, 2], name='vector')\n",
    "print('b.shape: ', b.shape)\n",
    "\n",
    "# constant of 2x2 tensor (matrix)\n",
    "c = tf.constant([[0,1], [2, 3]], name='matrix')\n",
    "print('c.shape: ', c.shape)\n",
    "\n",
    "print('\\n','Run session','\\n')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(a))\n",
    "    print(sess.run(b))\n",
    "    print(sess.run(c))\n",
    "    print('\\n','Graph definition', '\\n\\n',sess.graph.as_graph_def())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같이 constant외에도 다양한 상수 관련 함수가 있다.\n",
    "zeros, ones는 첫 파라미터가 shape이지만 fill은 shape이 아니고 dims이다.\n",
    "상세한 내용은 API 문서에서 확인하기 바란다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# 지정된 shape형태의 tensor에 값 0을 채운다.\n",
    "a = tf.zeros(shape=(2, 3))\n",
    "# 지정된 shape형태의 tensor에 값 1을 채운다.\n",
    "c = tf.ones(shape=(2, 3))\n",
    "# 지정된 tensor의 동일한 shape에 값 0을 채운다.\n",
    "b = tf.zeros_like(tensor=a)\n",
    "# 지정된 tensor의 동일한 shape에 값 1을 채운다.\n",
    "d = tf.ones_like(tensor=c)\n",
    "# dims에 지정된 형태에 value를 채워 tensor를 만든다. \n",
    "e = tf.fill(dims=[2,3], value=8)\n",
    "# Generates values in an interval.\n",
    "f = tf.lin_space(start=10.0, stop=13.0, num=4, name='linspace')\n",
    "\n",
    "start = 3\n",
    "limit = 18\n",
    "delta = 3\n",
    "\n",
    "g = tf.range(start, limit, delta)\n",
    "h = tf.range(limit)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('a', sess.run(a))\n",
    "    print('b', sess.run(b))\n",
    "    print('c', sess.run(c))\n",
    "    print('d', sess.run(d))\n",
    "    print('e', sess.run(e))\n",
    "    print('f', sess.run(f))\n",
    "    print('g', sess.run(g))\n",
    "    print('h', sess.run(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Variables\n",
    "\n",
    "* 앞에서 살펴본 tf.constant는 매소드이다. 하지만 tf.Variable은 여러게의 매소드로 구성된 클래스다.\n",
    "* Variable 값은 각 session에 종속적이다.\n",
    "* tf.Variable 직접 쓰지 말고 tf.get_variable을 사용하도록 한다.\n",
    "\n",
    "```python\n",
    "tf.get_variable(\n",
    "    name,\n",
    "    shape=None,\n",
    "    dtype=None,\n",
    "    initializer=None,\n",
    "    regularizer=None,\n",
    "    trainable=True,\n",
    "    collections=None,\n",
    "    caching_device=None,\n",
    "    partitioner=None,\n",
    "    validate_shape=True,\n",
    "    use_resource=None,\n",
    "    custom_getter=None,\n",
    "    constraint=None\n",
    ")\n",
    "```\n",
    "\n",
    "* tf.constant는 그래프에 상수화되어 저장되지만 Variable은 parameter server에 메모리 상에 저장된다.\n",
    "* Variable은 사용하기 전 초기화가 선행되어야 한다.\n",
    "\n",
    "* 다음 함수를 호출하면 지정된 initializer가 호출된다.\n",
    "```\n",
    "tf.global_variables_initializer()\n",
    "```\n",
    "* 그 밖에 Variable을 개별로 초기화를 해주는 방법과 assign을 이용하는 방법은 생략하겠다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "v = tf.get_variable(name='normal_init', shape=(3,3), initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "# 상수 텐서를 초기화에 사용할 경우, shape을 지정할 필요 없다.\n",
    "w = tf.get_variable(name='constant_init', initializer=tf.ones(shape=(3,)))\n",
    "\n",
    "m = v * w\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    _v, _w, _m = sess.run([v, w, m])\n",
    "    \n",
    "    print('_v:\\n', _v)\n",
    "    print('_w:\\n', _w)\n",
    "    print('_m:\\n', _m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable은 메모리 상의 변수로 존재하며 값을 업데이트 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.get_variable(name='scalar', initializer=tf.constant(10))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(x.initializer)\n",
    "    print(sess.run(x.assign_add(delta=10)))\n",
    "    print(sess.run(x.assign_sub(delta=2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.get_variable(name='scalar', initializer=tf.constant(10))\n",
    "\n",
    "with tf.Session() as sess1:\n",
    "    sess1.run(x.initializer)\n",
    "    print(sess1.run(x.assign_add(delta=10)))\n",
    "    \n",
    "with tf.Session() as sess2:\n",
    "    sess2.run(x.initializer)\n",
    "    print(sess2.run(x.assign_sub(delta=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Placeholders\n",
    "\n",
    "데이터를 그래프에 임포트하기 위해서는 placeholder를 지정해 줘야한다.\n",
    "\n",
    "```python\n",
    "tf.placeholder(\n",
    "    dtype,\n",
    "    shape=None,\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "\n",
    "* 과거에 사용하던 feed_dict를 이용해서 입력 값을 지정하던 방식은 지양하는 것이 좋다.\n",
    "* 뒤에 설명할 tf.data.Dataset을 이용하는 방법이 좋다.\n",
    "* placeholder의 shape 파라미터를 None으로 지정해도 되지면, 권장되지는 않으니 **꼭 지정해 주는 것이 좋다.**\n",
    "\n",
    "다음과 같이 간단히 살펴보기로 하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32)\n",
    "y = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "z = x + y\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(z, feed_dict={x: 3, y: 4.5}))\n",
    "    print(sess.run(z, feed_dict={x: [1, 3], y:[2, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 feed_dict을 이용한 디버깅 기법\n",
    "**placeholder 뿐만 아니라 constant, variable 모두 feedable object로 임의의 값을 지정하여 수식을 확인**할 수 있다.  \n",
    "해당 그래프가 정상적으로 동작하는지 확인할 때, 아주 유용하니 꼭 알아두기 바란다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 3\n",
    "features = 2\n",
    "n_hiden = 3\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(batch_size, features), name='batch_input')\n",
    "print('x shape: ', x)\n",
    "w = tf.get_variable(name='weights', dtype=tf.float32, shape=(features, n_hiden))\n",
    "print('w shape: ', w)\n",
    "b = tf.get_variable(name='bias', dtype=tf.float32, shape=(1, n_hiden))\n",
    "print('b shape: ', b)\n",
    "\n",
    "m = tf.matmul(x, w)\n",
    "print('m shape: ', m)\n",
    "\n",
    "result = tf.add(m, b)\n",
    "print('result shape: ', result)\n",
    "\n",
    "tf.summary.FileWriter('./log', tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    feed_dict = {\n",
    "        x: [[1, 2],\n",
    "            [3, 4],\n",
    "            [5, 6]],\n",
    "\n",
    "        w: [[1, 2, 3],\n",
    "            [3, 4, 5]],\n",
    "\n",
    "        b: [[10, 10, 10]]\n",
    "    }\n",
    "    _m, _result = sess.run([m, result], feed_dict=feed_dict)\n",
    "    print('_m:\\n', _m)\n",
    "    print('_result:\\n', _result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Control flow\n",
    "\n",
    "tensorflow는 Graph에 조건에 따른 분기를 추가하기 위해서 다양한 함수를 제공한다. <br/>\n",
    "여기서는 기본이 되는 tf.cond를 살펴보기로 하겠다.\n",
    "\n",
    "```python\n",
    "tf.cond(\n",
    "    pred,\n",
    "    true_fn=None,\n",
    "    false_fn=None,\n",
    "    strict=False,\n",
    "    name=None,\n",
    "    fn1=None,\n",
    "    fn2=None\n",
    ")\n",
    "```\n",
    "\n",
    "예제는 Huber loss를 사용하겠다. 상세한 내용은 [링크](https://en.wikipedia.org/wiki/Huber_loss)를 참고하기 바란다.<br/>\n",
    "Huber loss function은 다음과 같다.\n",
    "\n",
    "![alt Huberloss](img/huberloss.svg)\n",
    "\n",
    "델타 값을 기준으로 Loss값이 다르게 생성된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def huber_loss(label, prediction, delta):\n",
    "    residual = tf.abs(label - prediction)\n",
    "    def f1(): return 0.5 * tf.square(residual)\n",
    "    def f2(): return delta * residual - 0.5 * tf.square(delta)\n",
    "    return tf.cond(tf.less(residual, delta), f1, f2)\n",
    "\n",
    "label = tf.placeholder(name='lable', shape=[], dtype=tf.float32)\n",
    "prediction = tf.placeholder(name='prediction', shape=[], dtype=tf.float32)\n",
    "\n",
    "loss = huber_loss(label, prediction, 4.0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(loss, feed_dict={ label: 1, prediction: 3})) # 0.5 * 2.0 * 2.0\n",
    "    print(sess.run(loss, feed_dict={ label: 1, prediction: 11})) # (4.0 * 10) - (0.5 * 4.0 * 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Embedding Lookup\n",
    "\n",
    "딥러닝 활용에 있어서 Embedding은 아주 중요한 부분이다.  \n",
    "tensorflow는 다음과 같이 embedding lookup 함수를 재공하여 내부에 weights를 반환 할 수 있도록 해주고 있다.  \n",
    "다음은 embedding lookup 동작 방식을 그림으로 나타낸 것이다.  \n",
    "\n",
    "\n",
    "![alt embedding](img/matrix_mult_w_one_hot.png)\n",
    "\n",
    "\n",
    "함수 원형은 다음과 같다.\n",
    "\n",
    "```python\n",
    "tf.nn.embedding_lookup(\n",
    "    params,\n",
    "    ids,\n",
    "    partition_strategy='mod',\n",
    "    name=None,\n",
    "    validate_indices=True,\n",
    "    max_norm=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "VOCAB_SIZE = 5\n",
    "EMBED_SIZE = 3\n",
    "\n",
    "one_hot_selector = tf.placeholder(name='selector', shape=(), dtype=tf.int64)\n",
    "\n",
    "embed_matrix = tf.get_variable('embed_matrix',\n",
    "                               shape=[VOCAB_SIZE, EMBED_SIZE],\n",
    "                               initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "embed = tf.nn.embedding_lookup(embed_matrix, one_hot_selector, name='embedding')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    feed_dict={\n",
    "        one_hot_selector : 2,\n",
    "        embed_matrix : [\n",
    "            [0,0,0],\n",
    "            [1,1,1],\n",
    "            [2,2,2],\n",
    "            [3,3,3],\n",
    "            [4,4,4],\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(sess.run(embed, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset\n",
    "\n",
    "딥러닝으로 시스템을 구성하거나 다양한 학습데이터 학습하기 위해서 입력 데이터 구성은 아주 중요하다.<br/>\n",
    "때로는 모델을 디자인하고 만드는 것보다 데이터 파이프 라인을 구성하는데 더 오랜 시간이 걸리기도 한다. <br/>\n",
    "외부에서 데이터를 가공하여 placeholder에 feed_dict를 이용해서 직접 데이터를 넣어 주는 방식을 지양하는 것이 좋다.<br/>\n",
    "\n",
    "**tf.data.Dataset은 이전 방식과는 다르게 그래프에 일부로** 실행되도록 만들어 졌다. <br/>\n",
    "다음은 실제로 데이터를 연결하는 함수이다.\n",
    "\n",
    "로컬 메모리에 데이터를 저장하고 데이터를 읽어 올때는 다음 함수를 사용할 수 있다. <br/>\n",
    "numpy 배열을 파라미터로 입력될 경우 해당 배열은 tensor로 변환 된다.\n",
    " \n",
    "\n",
    "```python\n",
    "@staticmethod\n",
    "from_tensor_slices(tensors)\n",
    "```\n",
    "\n",
    "데이터량이 많아서 DB와 같이 원격 데이터에서 데이터를 불러올 때는 다음 함수가 효율적이다.\n",
    "\n",
    "```python\n",
    "@staticmethod\n",
    "from_generator(\n",
    "    generator,\n",
    "    output_types,\n",
    "    output_shapes=None,\n",
    "    args=None\n",
    ")\n",
    "```\n",
    "\n",
    "dataset을 사용하기 위해서 다음과 같이 iterator와 입력을 그래프에 연결하기 위한 tensor가 필요하다.  \n",
    "get_next() 함수는 그래프를 생성하기 위한 tensor를 반환한다는 점을 명심하기 바란다.  \n",
    "\n",
    "```python\n",
    "dataset = tf.data.Dataset.from_tensor_slices(source)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "tensor = iterator.get_next()\n",
    "```\n",
    "\n",
    "다음 두 예제는 여러 데이터 소스로 부터 데이터를 묶어서 하나의 dataset을 구성하는 방법과 Dictionary를 사용하는 방법을 보여준다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_types:  <dtype: 'float32'>\n",
      "output_shapes:  (10,)\n",
      "output_types:  (tf.float32, tf.float32)\n",
      "output_shapes:  (TensorShape([Dimension(100)]), TensorShape([]))\n",
      "(tf.float32, (tf.float32, tf.float32))\n",
      "(TensorShape([Dimension(10)]), (TensorShape([Dimension(100)]), TensorShape([])))\n"
     ]
    }
   ],
   "source": [
    "source = tf.random_uniform(shape=(4, 10), minval=0, maxval=100)\n",
    "# 입력 소스로 부터 dataset을 구성\n",
    "dataset1 = tf.data.Dataset.from_tensor_slices(source)\n",
    "\n",
    "print('output_types: ', dataset1.output_types)\n",
    "print('output_shapes: ', dataset1.output_shapes)\n",
    "\n",
    "inputs = tf.random_uniform(shape=(4, 100))\n",
    "labels = tf.random_uniform(shape=(4,))\n",
    "\n",
    "# 다른 입력 소스를 묶어서 dataset을 구성\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
    "\n",
    "print('output_types: ', dataset2.output_types)\n",
    "print('output_shapes: ', dataset2.output_shapes)\n",
    "\n",
    "# dataset을 묶어서 새로운 dataset을 구성\n",
    "dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "\n",
    "print(dataset3.output_types)\n",
    "print(dataset3.output_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': tf.float32, 'b': tf.float32}\n",
      "{'a': TensorShape([]), 'b': TensorShape([Dimension(100)])}\n"
     ]
    }
   ],
   "source": [
    "# 딕셔너리를 이용한 입력소스 지정 방법. key에 이름을 부여할 수 있음\n",
    "sources = dict()\n",
    "\n",
    "sources['a'] = tf.random_uniform(shape=(4,))\n",
    "sources['b'] = tf.random_uniform(shape=(4, 100))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(sources)\n",
    "\n",
    "print(dataset.output_types)\n",
    "print(dataset.output_shapes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Iterator\n",
    "iterator 사용 시, 다음과 같이 try-except구문을 사용해서 OutOfRangeError 체크를 반드시 해주는 것이 좋다.\n",
    "\n",
    "```python\n",
    "try:\n",
    "    do something\n",
    "except tf.errors.OutOfRangeError:\n",
    "    break\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 one-shot iterator\n",
    "* initialization이 필요 없다. 사실 initialization을 수행하면 에러가 발생한다.\n",
    "* 끝에 도착하면 다시 재활용할 수 없다. 결국, epoch마다 사용 불가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)         # <class 'tensorflow.python.data.ops.dataset_ops.RangeDataset'>\n",
    "iterator = dataset.make_one_shot_iterator() # <class 'tensorflow.python.data.ops.iterator_ops.Iterator'>\n",
    "next_element = iterator.get_next()          # <class 'tensorflow.python.framework.ops.Tensor'>\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:  \n",
    "          print(sess.run(next_element))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 initalizable iterator\n",
    "* 사용전, initialization 필수\n",
    "* epoch마다 재 활용할 수 있다.\n",
    "* tf.placeholder를 이용해서 동작을 지정할 있는 장점이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:  0\n",
      "epoch 0:  1\n",
      "epoch 0:  2\n",
      "epoch 0:  3\n",
      "epoch 0:  4\n",
      "epoch 0:  5\n",
      "epoch 0:  6\n",
      "epoch 0:  7\n",
      "epoch 0:  8\n",
      "epoch 0:  9\n",
      "epoch 0:  10\n",
      "epoch 0:  11\n",
      "epoch 0:  12\n",
      "epoch 0:  13\n",
      "epoch 0:  14\n",
      "epoch 0:  15\n",
      "epoch 0:  16\n",
      "epoch 0:  17\n",
      "epoch 0:  18\n",
      "epoch 0:  19\n",
      "\n",
      "\n",
      "epoch 1:  0\n",
      "epoch 1:  1\n",
      "epoch 1:  2\n",
      "epoch 1:  3\n",
      "epoch 1:  4\n",
      "epoch 1:  5\n",
      "epoch 1:  6\n",
      "epoch 1:  7\n",
      "epoch 1:  8\n",
      "epoch 1:  9\n",
      "epoch 1:  10\n",
      "epoch 1:  11\n",
      "epoch 1:  12\n",
      "epoch 1:  13\n",
      "epoch 1:  14\n",
      "epoch 1:  15\n",
      "epoch 1:  16\n",
      "epoch 1:  17\n",
      "epoch 1:  18\n",
      "epoch 1:  19\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_value = tf.placeholder(tf.int64, shape=())\n",
    "dataset = tf.data.Dataset.range(max_value)\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    for epoch in range(2):\n",
    "        sess.run(iterator.initializer, feed_dict={max_value: 20})\n",
    "        while True:\n",
    "            try:\n",
    "                print(f'epoch {epoch}: ', sess.run(next_element))\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "            \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 reinitilizable iterator\n",
    "* 여러 Data source로 부터 데이터를 가지고 올수 있다. 단, structure은 동일해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.range(10).map(lambda x: x + tf.random_uniform([], -10, 10, tf.int64))\n",
    "validation_dataset = tf.data.Dataset.range(5)\n",
    "\n",
    "# reinitializable iterator의 경우는 structure로 정의된다.\n",
    "# 다른 Data source라 할지라도 같은 데이터 형태를 가지기 때문에 둘 중 하나를 사용하면 된다.\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types, training_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "validation_init_op = iterator.make_initializer(validation_dataset)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    #The number of epochs\n",
    "    for e in range(20):\n",
    "        print(f'> epoch {e}')\n",
    "        \n",
    "        # train sequence가 초기화 된다.\n",
    "        sess.run(training_init_op)\n",
    "        for _ in range(10):\n",
    "            print(f'train: {sess.run(next_element)}')\n",
    "        # validation sequence가 초기화 된다.\n",
    "        sess.run(validation_init_op)\n",
    "        for _ in range(5):\n",
    "            print(f'valid: {sess.run(next_element)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 feedable iterator\n",
    "* reinitializable iterator와 동일 기능 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat함수를 이용해서 반복되는 sequence를 생성할 수 있다.\n",
    "# repeat함수를 사용하지 않으면 범위를 벗어날 경우, OutOfRangeError가 발생한다.\n",
    "training_dataset = tf.data.Dataset.range(10).repeat()\n",
    "validation_dataset = tf.data.Dataset.range(5)\n",
    "\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(handle, \n",
    "                                               validation_dataset.output_types, \n",
    "                                               validation_dataset.output_shapes)\n",
    "\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "training_iterator = training_dataset.make_one_shot_iterator()\n",
    "validation_iterator = validation_dataset.make_initializable_iterator()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # input 소스를 선택할 수 있는 핸들러\n",
    "    training_handle = sess.run(training_iterator.string_handle())\n",
    "    validation_handle = sess.run(validation_iterator.string_handle())\n",
    "    \n",
    "    while True:\n",
    "        for _ in range(200):\n",
    "            print('train ', sess.run(next_element, feed_dict={handle: training_handle}))\n",
    "\n",
    "        sess.run(validation_iterator.initializer)\n",
    "        for _ in range(5):\n",
    "            print('valid ', sess.run(next_element, feed_dict={handle: validation_handle}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(3)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "result = tf.add(next_element, next_element)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "   \n",
    "    # 일반적으로 train loop에 사용하는 try-except 블록\n",
    "    try:\n",
    "        print(sess.run(result)) # 0\n",
    "        print(sess.run(result)) # 1\n",
    "        print(sess.run(result)) # 2\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('End of dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices(['A', 'B', 'C'])\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices(([1, 2, 3], ['A1', 'B1', 'C1']))\n",
    "dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "\n",
    "iterator = dataset3.make_initializable_iterator()\n",
    "next1, (next2, next3) = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "    print(sess.run((next1, (next2, next3))))\n",
    "    # iterator에 묶여 있어서 동시에 다음 element로 넘어간다.\n",
    "    print(sess.run(next1)) \n",
    "    print(sess.run((next1, (next2, next3))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Reading input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Consuming NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "y = np.array([0, 1])\n",
    "\n",
    "np.savez('./array', features=x, labels=y)\n",
    "data = np.load('array.npz')\n",
    "\n",
    "features = data['features']\n",
    "labels = data['labels']\n",
    "\n",
    "# The length of features and labels should be the same.\n",
    "assert features.shape[0] == labels.shape[0]\n",
    "\n",
    "feature_placeholder = tf.placeholder(features.dtype, features.shape)\n",
    "labels_placeholder = tf.placeholder(labels.dtype, labels.shape)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((feature_placeholder, labels_placeholder))\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer, feed_dict={feature_placeholder: features, labels_placeholder: labels})\n",
    "    print(sess.run(next_element))\n",
    "    print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Consuming TFRecord data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Consuming text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Preprocessing data with Dataset.map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Parsing tf.Example protocol buffer messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Decoding image data and resizing it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Applying arbitrary Python logic with tf.py_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Batching dataset elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Simple batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inc_dataset = tf.data.Dataset.range(100)\n",
    "dec_dataset = tf.data.Dataset.range(0, -100, -1)\n",
    "dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))\n",
    "# basch 사이즈 지정\n",
    "\n",
    "batched_dataset = dataset.batch(4)\n",
    "\n",
    "iterator = batched_dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(next_element))  # ==> ([0, 1, 2,   3],   [ 0, -1,  -2,  -3])\n",
    "    print(sess.run(next_element))  # ==> ([4, 5, 6,   7],   [-4, -5,  -6,  -7])\n",
    "    print(sess.run(next_element))  # ==> ([8, 9, 10, 11],   [-8, -9, -10, -11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Batching tensors with padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name scope\n",
    "\n",
    "먼저 Name scope가 적용되지 않은 그래프를 tensorboard에서 확인해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "FEATURES = 100\n",
    "\n",
    "features = tf.placeholder(tf.int64, shape=[BATCH_SIZE, ])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
