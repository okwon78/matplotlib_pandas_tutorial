{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상수를 더하기 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(3.0, dtype=tf.float32)\n",
    "b = tf.constant(4.0)\n",
    "\n",
    "total = a + b\n",
    "\n",
    "# tensorboard를 위해 그래프 추가\n",
    "writer = tf.summary.FileWriter('.')\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run({'ab':(a, b), 'total':total}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프의 동작 방식을 이해하기 위한 예제이다. 다음은 그래프가 3번 실행 된다.\n",
    "마지막 실행에서 out1, out2가 동일한 vec값을 사용했다는 점을 확인하기 바란다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#변수 3개 반환\n",
    "vec = tf.random_uniform(shape=(3,))\n",
    "out1 = vec + 1\n",
    "out2 = vec + 2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('vec: {}'.format(sess.run(vec)))\n",
    "    print('vec: {}'.format(sess.run(vec)))\n",
    "    # out1, out2가 동일한 vec을 사용했다\n",
    "    print('out: {}'.format(sess.run((out1, out2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 값을 넣기 위해 placeholder를 추가한 내용이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "z = x + y\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(z, feed_dict={x: 3, y: 4.5}))\n",
    "    print(sess.run(z, feed_dict={x: [1, 3], y:[2, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[2 3]\n",
      "[4 5]\n",
      "[6 7]\n"
     ]
    }
   ],
   "source": [
    "source = np.array([\n",
    "    [0, 1],\n",
    "    [2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7],\n",
    "])\n",
    "\n",
    "slices = tf.data.Dataset.from_tensor_slices(my_data)\n",
    "iterator = slices.make_one_shot_iterator()\n",
    "next_item = iterator.get_next()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        print(sess.run(next_item))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [ 0.4575673  2.846385  -2.4032662]\n",
      "2 [-0.38465163  0.5436408  -1.5063286 ]\n",
      "3 [ 1.4354113  -0.63497657 -1.0856948 ]\n",
      "4 [0.10020169 0.51569295 0.27205357]\n",
      "5 [ 1.1109571  0.686919  -2.1738098]\n",
      "6 [-1.0901219  -0.86027545  0.5627439 ]\n",
      "7 [-0.49117967  0.08140505  0.7198881 ]\n",
      "8 [-0.5775051  -0.12095883 -0.45476007]\n",
      "9 [-1.1111729  -0.98800325  0.3664406 ]\n",
      "10 [0.53594863 0.17011186 0.258575  ]\n"
     ]
    }
   ],
   "source": [
    "my_data = tf.random_normal([10, 3])\n",
    "slices = tf.data.Dataset.from_tensor_slices(my_data)\n",
    "iterator = slices.make_initializable_iterator()\n",
    "next_row = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "    \n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            i+=1\n",
    "            print(i, sess.run(next_row))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n",
      "(10,)\n",
      "(tf.float32, tf.float32)\n",
      "(TensorShape([]), TensorShape([Dimension(100)]))\n",
      "(tf.float32, (tf.float32, tf.float32))\n",
      "(TensorShape([Dimension(10)]), (TensorShape([]), TensorShape([Dimension(100)])))\n"
     ]
    }
   ],
   "source": [
    "# 입력 소스로 부터 dataset을 구성\n",
    "dataset1 = tf.data.Dataset.from_tensor_slices(tf.random_uniform([4, 10], minval=0, maxval=100))\n",
    "print(dataset1.output_types)\n",
    "print(dataset1.output_shapes)\n",
    "\n",
    "# 다른 입력 소스를 묶어서 dataset을 구성\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.random_uniform([4]), tf.random_uniform([4, 100]))\n",
    ")\n",
    "\n",
    "print(dataset2.output_types)\n",
    "print(dataset2.output_shapes)\n",
    "\n",
    "# dataset을 묶어서 새로운 dataset을 구성\n",
    "dataset3 = tf.data.Dataset.zip(\n",
    "    (dataset1, dataset2)\n",
    ")\n",
    "print(dataset3.output_types)\n",
    "print(dataset3.output_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': tf.float32, 'b': tf.float32}\n",
      "{'a': TensorShape([]), 'b': TensorShape([Dimension(100)])}\n"
     ]
    }
   ],
   "source": [
    "# 딕셔너리를 이용한 입력소스 지정 방법. key에 이름을 부여할 수 있음\n",
    "sources = dict()\n",
    "\n",
    "sources['a'] = tf.random_uniform([4])\n",
    "sources['b'] = tf.random_uniform([4, 100])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(sources)\n",
    "\n",
    "print(dataset.output_types)\n",
    "print(dataset.output_shapes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# one-shot iterator\n",
    "# initialization이 필요 없다.\n",
    "\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "      print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# initalizable iterator\n",
    "# 사용전, initialization 필수\n",
    "# tf.placeholder를 이용해서 동작을 지정할 있는 장점이 있다.\n",
    "\n",
    "max_value = tf.placeholder(tf.int64, shape=[])\n",
    "dataset = tf.data.Dataset.range(max_value)\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer, feed_dict={max_value: 20})\n",
    "    for i in range(10):\n",
    "        print(sess.run(next_element))\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer, feed_dict={max_value:5})\n",
    "    for i in range(5):\n",
    "        print(sess.run(next_element))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinitilizable iterator\n",
    "# 여러 Data source로 부터 데이터를 가지고 올수 있다.\n",
    "\n",
    "training_dataset = tf.data.Dataset.range(100)\n",
    "training_dataset.map(lambda x: x + tf.random_uniform([], -10, 10, tf.int64))\n",
    "validation_dataset = tf.data.Dataset.range(100)\n",
    "\n",
    "# reinitializable iterator의 경우는 structure로 정의된다.\n",
    "# 다른 Data source라 할지라도 같은 데이터 형태를 가지기 때문에 둘 중 하나를 사용하면 된다.\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types, training_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "iterator = \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
