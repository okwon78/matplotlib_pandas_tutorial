{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단하게 그래프를 생성해서 tensorboard를 통해 살펴보기로 하자. <br/>\n",
    "현재 working directory에 ./log에 로그를 저장하도록 한다.\n",
    "\n",
    "현재 그래프를 반환한다.\n",
    "```\n",
    "tf.get_default_graph()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ab': (3.0, 4.0), 'total': 7.0} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "a = tf.constant(3.0, dtype=tf.float32)\n",
    "b = tf.constant(4.0)\n",
    "\n",
    "total = a + b\n",
    "\n",
    "# tensorboard를 위해 그래프 추가\n",
    "# 그래프가 완성된 뒤 추가 되어야 한다.\n",
    "writer = tf.summary.FileWriter('./log', tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run({'ab':(a, b), 'total':total}), '\\n')\n",
    "    \n",
    "# print(tf.get_default_graph().as_graph_def())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Tensorboard\n",
    "\n",
    "포트를 특별히 지정하지 않으면, 디폴트 포트는 6006이다.<br/>\n",
    "tensorboard의 실행 방법은 다음과 같다.\n",
    "\n",
    "```\n",
    "$ tensorboard --logdir=<path> --port=6006\n",
    "```\n",
    "\n",
    "위 예제 실행은 다음과 같다.\n",
    "\n",
    "```\n",
    "$ tensorboard --logdir=./log --port=6006\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프의 동작 방식을 이해하기 위한 예제이다.<br/>\n",
    "다음은 그래프가 3번 실행 된다.<br/>\n",
    "마지막 실행에서 out1, out2가 동일한 vec값을 사용했다는 점을 확인하기 바란다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec: [0.8685545  0.15405309 0.16789365]\n",
      "vec: [0.95555186 0.9513595  0.7278329 ]\n",
      "out: (array([1.3245795, 1.9598197, 1.9704139], dtype=float32), array([2.3245795, 2.9598198, 2.970414 ], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#변수 3개 반환\n",
    "vec = tf.random_uniform(shape=(3,))\n",
    "out1 = vec + 1\n",
    "out2 = vec + 2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('vec: {}'.format(sess.run(vec)))\n",
    "    print('vec: {}'.format(sess.run(vec)))\n",
    "    # out1, out2가 동일한 vec을 사용했다\n",
    "    print('out: {}'.format(sess.run((out1, out2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프에 임의의 상수값을 지정하여 추가할 수 있다.\n",
    "\n",
    "```python\n",
    "tf.constant(\n",
    "    value,\n",
    "    dtype=None,\n",
    "    shape=None,\n",
    "    name='Const',\n",
    "    verify_shape=False\n",
    ")\n",
    "```\n",
    "\n",
    "지정된 상수는 그래프와 함께 저장된다.<br/>\n",
    "다음과 같이 값을 지정해서 텐서를 생성할 수 있다.<br/>\n",
    "첫번째 파라미터가 shape이 아닌 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "(2,)\n",
      "(2, 2)\n",
      "2\n",
      "[2 2]\n",
      "[[0 1]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# constant of 0d tensor (scalar)\n",
    "a = tf.constant(2, name='scalar')\n",
    "# constant of 1d tensor (vector)\n",
    "b = tf.constant([2, 2], name='vector')\n",
    "# constant of 2x2 tensor (matrix)\n",
    "c = tf.constant([[0,1], [2, 3]], name='matrix')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(a))\n",
    "    print(sess.run(b))\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constant외에도 다양한 상수 관련 함수가 있으니 API 문서에서 확인하기 바란다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "b [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "c [[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "d [[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "e [[8 8 8]\n",
      " [8 8 8]]\n",
      "f [10. 11. 12. 13.]\n",
      "g [ 3  6  9 12 15]\n",
      "h [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "a = tf.zeros([2, 3])\n",
    "b = tf.zeros_like(a)\n",
    "c = tf.ones([2, 3])\n",
    "d = tf.ones_like(c)\n",
    "e = tf.fill([2,3], 8)\n",
    "f = tf.lin_space(10.0, 13.0, 4, name='linspace')\n",
    "start = 3\n",
    "limit = 18\n",
    "delta = 3\n",
    "g = tf.range(start, limit, delta)\n",
    "h = tf.range(limit)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('a', sess.run(a))\n",
    "    print('b', sess.run(b))\n",
    "    print('c', sess.run(c))\n",
    "    print('d', sess.run(d))\n",
    "    print('e', sess.run(e))\n",
    "    print('f', sess.run(f))\n",
    "    print('g', sess.run(g))\n",
    "    print('h', sess.run(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Variables\n",
    "\n",
    "* 앞에서 살펴본 tf.constant는 함수이다. 하지만 tf.Variable은 여러게의 함수로 구성된 클래스다.\n",
    "* tf.Variable 쓰지 말고 tf.get_variable을 사용하도록 한다.\n",
    "\n",
    "```python\n",
    "tf.get_variable(\n",
    "    name,\n",
    "    shape=None,\n",
    "    dtype=None,\n",
    "    initializer=None,\n",
    "    regularizer=None,\n",
    "    trainable=True,\n",
    "    collections=None,\n",
    "    caching_device=None,\n",
    "    partitioner=None,\n",
    "    validate_shape=True,\n",
    "    use_resource=None,\n",
    "    custom_getter=None,\n",
    "    constraint=None\n",
    ")\n",
    "```\n",
    "\n",
    "* tf.constant는 그래프에 상수화되어 저장되지만 Variable은 parameter server에 메모리 상에 저장된다.\n",
    "* Variable은 사용하기 전 초기화가 선행되어야 한다.\n",
    "\n",
    "* 다음 함수를 호출하면 지정된 initializer가 호출된다.\n",
    "```\n",
    "tf.global_variables_initializer()\n",
    "```\n",
    "* 그 밖에 Variable을 개별로 초기화를 해주는 방법과 assign을 이용하는 방법은 생략하겠다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5987738  -1.3011031  -0.2660086 ]\n",
      " [ 1.633186    0.15406503 -0.8655053 ]\n",
      " [-1.1830344  -1.8143717   1.269143  ]]\n"
     ]
    }
   ],
   "source": [
    "# 같은 이름의 variable을 그래프에 추가할 수 없기 때문에 그래프를 리셋해줘야 한다.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "v = tf.get_variable(name='normal_matrix', shape=(3,3), initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Placeholders\n",
    "\n",
    "데이터를 그래프에 임포트하기 위해서는 placeholder를 지정해 줘야한다.\n",
    "\n",
    "```python\n",
    "tf.placeholder(\n",
    "    dtype,\n",
    "    shape=None,\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "\n",
    "* 과거에 사용하던 feed_dict를 이용해서 입력 값을 지정하던 방식은 지양하는 것이 좋다.\n",
    "* 뒤에 설명할 tf.data.Dataset을 이용하는 방법이 좋다.\n",
    "* placeholder의 shape 파라미터를 None으로 지정해도 되지면, 권장되지는 않으니 꼭 지정해 주는 것이 좋다.\n",
    "\n",
    "다음과 같이 간단히 살펴보기로 하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "z = x + y\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(z, feed_dict={x: 3, y: 4.5}))\n",
    "    print(sess.run(z, feed_dict={x: [1, 3], y:[2, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 feed_dict을 이용한 디버깅 기법\n",
    "placeholder 뿐만 아니라 constant, variable 모두 feedable object로 임의의 값을 지정하여 수식을 확인할 수 있다. <br/>\n",
    "해당 그래프가 정상적으로 동작하는지 확인할 때, 아주 유용하니 꼭 알아두기 바란다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 7., 10., 13.],\n",
      "       [15., 22., 29.],\n",
      "       [23., 34., 45.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 3\n",
    "features = 2\n",
    "n_hiden = 3\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[batch_size, features], name='batch_input')\n",
    "\n",
    "w = tf.get_variable(name='weights', dtype=tf.float32, shape=(features, n_hiden))\n",
    "b = tf.get_variable(name='bias', dtype=tf.float32, shape=(1, n_hiden))\n",
    "\n",
    "m = tf.matmul(x, w)\n",
    "result = tf.add(m, b)\n",
    "\n",
    "tf.summary.FileWriter('./log', tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    feed_dict = {\n",
    "        x: [[1, 2],\n",
    "            [3, 4],\n",
    "            [5, 6]],\n",
    "\n",
    "        w: [[1, 2, 3],\n",
    "            [3, 4, 5]],\n",
    "\n",
    "        b: [[10, 10, 10]]\n",
    "    }\n",
    "\n",
    "    print(sess.run([m], feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Control flow\n",
    "\n",
    "tensorflow는 Graph에 조건에 따른 분기를 추가하기 위해서 다양한 함수를 제공한다. <br/>\n",
    "여기서는 기본이 되는 tf.cond를 살펴보기로 하겠다.\n",
    "\n",
    "```python\n",
    "tf.cond(\n",
    "    pred,\n",
    "    true_fn=None,\n",
    "    false_fn=None,\n",
    "    strict=False,\n",
    "    name=None,\n",
    "    fn1=None,\n",
    "    fn2=None\n",
    ")\n",
    "```\n",
    "\n",
    "예제는 Huber loss를 사용하겠다. 상세한 내용은 [링크](https://en.wikipedia.org/wiki/Huber_loss)를 참고하기 바란다.<br/>\n",
    "Huber loss function은 다음과 같다.\n",
    "\n",
    "![alt Huberloss](img/huberloss.svg)\n",
    "\n",
    "델타 값을 기준으로 Loss값이 다르게 생성된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "32.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def huber_loss(label, prediction, delta):\n",
    "    residual = tf.abs(label - prediction)\n",
    "    def f1(): return 0.5 * tf.square(residual)\n",
    "    def f2(): return delta * residual - 0.5 * tf.square(delta)\n",
    "    return tf.cond(tf.less(residual, delta), f1, f2)\n",
    "\n",
    "label = tf.placeholder(name='lable', shape=[], dtype=tf.float32)\n",
    "prediction = tf.placeholder(name='prediction', shape=[], dtype=tf.float32)\n",
    "\n",
    "loss = huber_loss(label, prediction, 4.0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(loss, feed_dict={ label: 1, prediction: 3})) # 0.5 * 2.0 * 2.0\n",
    "    print(sess.run(loss, feed_dict={ label: 1, prediction: 11})) # (4.0 * 10) - (0.5 * 4.0 * 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Dataset\n",
    "\n",
    "딥러닝으로 시스템을 구성하거나 다양한 학습데이터 학습하기 위해서 입력 데이터 구성은 아주 중요하다.<br/>\n",
    "때로는 모델을 디자인하고 만드는 것보다 데이터 파이프 라인을 구성하는데 더 오랜 시간이 걸리기도 한다. <br/>\n",
    "외부에서 데이터를 가공하여 placeholder에 feed_dict를 이용해서 직접 데이터를 넣어 주는 방식을 지양하는 것이 좋다.<br/>\n",
    "tf.data.Dataset을 반드시 익혀서 사용하도록 하도록 하자\n",
    "\n",
    "```python\n",
    "@staticmethod\n",
    "from_tensor_slices(tensors)\n",
    "```\n",
    "\n",
    "```python\n",
    "@staticmethod\n",
    "from_generator(\n",
    "    generator,\n",
    "    output_types,\n",
    "    output_shapes=None,\n",
    "    args=None\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = np.array([\n",
    "    [0, 1],\n",
    "    [2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7],\n",
    "])\n",
    "\n",
    "slices = tf.data.Dataset.from_tensor_slices(source)\n",
    "# 초기화 필요 없다.\n",
    "iterator = slices.make_one_shot_iterator()\n",
    "next_item = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    idx = 0\n",
    "    while True:\n",
    "        try:\n",
    "            idx += 1\n",
    "            print(f'{idx}: ',sess.run(next_item))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source = tf.random_normal(shape=[10, 3])\n",
    "slices = tf.data.Dataset.from_tensor_slices(source)\n",
    "# 초기화 필요. (뒤에서 추가 설명)\n",
    "iterator = slices.make_initializable_iterator()\n",
    "next_row = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "    \n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            i+=1\n",
    "            print(i, sess.run(next_row))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = tf.random_uniform([4, 10], minval=0, maxval=100)\n",
    "# 입력 소스로 부터 dataset을 구성\n",
    "dataset1 = tf.data.Dataset.from_tensor_slices(source)\n",
    "\n",
    "print(dataset1.output_types)\n",
    "print(dataset1.output_shapes)\n",
    "\n",
    "inputs = tf.random_uniform([4, 100])\n",
    "labels = tf.random_uniform([4])\n",
    "\n",
    "# 다른 입력 소스를 묶어서 dataset을 구성\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
    "\n",
    "print(dataset2.output_types)\n",
    "print(dataset2.output_shapes)\n",
    "\n",
    "# dataset을 묶어서 새로운 dataset을 구성\n",
    "dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "\n",
    "print(dataset3.output_types)\n",
    "print(dataset3.output_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딕셔너리를 이용한 입력소스 지정 방법. key에 이름을 부여할 수 있음\n",
    "sources = dict()\n",
    "\n",
    "sources['a'] = tf.random_uniform([4])\n",
    "sources['b'] = tf.random_uniform([4, 100])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(sources)\n",
    "\n",
    "print(dataset.output_types)\n",
    "print(dataset.output_shapes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Iterator\n",
    "iterator 사용 시,range 체크를 반드시 해주는 것이 좋다.\n",
    "\n",
    "```python\n",
    "try:\n",
    "    do something\n",
    "except tf.errors.OutOfRangeError:\n",
    "    break\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 one-shot iterator\n",
    "* initialization이 필요 없다. (할 수 없다)\n",
    "* 끝에 도착하면 다시 재활용할 수 없다. 결국, epoch마다 사용 불가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:  \n",
    "          print(sess.run(next_element))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 initalizable iterator\n",
    "* 사용전, initialization 필수\n",
    "* epoch마다 재 활용할 수 있다.\n",
    "* tf.placeholder를 이용해서 동작을 지정할 있는 장점이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = tf.placeholder(tf.int64, shape=[])\n",
    "dataset = tf.data.Dataset.range(max_value)\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    for epoch in range(2):\n",
    "        sess.run(iterator.initializer, feed_dict={max_value: 20})\n",
    "        while True:\n",
    "            try:\n",
    "                print(f'epoch {epoch}: ', sess.run(next_element))\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "            \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 reinitilizable iterator\n",
    "* 여러 Data source로 부터 데이터를 가지고 올수 있다. 단, structure은 동일해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.range(10).map(lambda x: x + tf.random_uniform([], -10, 10, tf.int64))\n",
    "validation_dataset = tf.data.Dataset.range(5)\n",
    "\n",
    "# reinitializable iterator의 경우는 structure로 정의된다.\n",
    "# 다른 Data source라 할지라도 같은 데이터 형태를 가지기 때문에 둘 중 하나를 사용하면 된다.\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types, training_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "validation_init_op = iterator.make_initializer(validation_dataset)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    #The number of epochs\n",
    "    for e in range(20):\n",
    "        print(f'> epoch {e}')\n",
    "        \n",
    "        # train sequence가 초기화 된다.\n",
    "        sess.run(training_init_op)\n",
    "        for _ in range(10):\n",
    "            print(f'train: {sess.run(next_element)}')\n",
    "        # validation sequence가 초기화 된다.\n",
    "        sess.run(validation_init_op)\n",
    "        for _ in range(5):\n",
    "            print(f'valid: {sess.run(next_element)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 feedable iterator\n",
    "* reinitializable iterator와 동일 기능 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat함수를 이용해서 반복되는 sequence를 생성할 수 있다.\n",
    "# repeat함수를 사용하지 않으면 범위를 벗어날 경우, OutOfRangeError가 발생한다.\n",
    "training_dataset = tf.data.Dataset.range(10).repeat()\n",
    "validation_dataset = tf.data.Dataset.range(5)\n",
    "\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(handle, \n",
    "                                               validation_dataset.output_types, \n",
    "                                               validation_dataset.output_shapes)\n",
    "\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "training_iterator = training_dataset.make_one_shot_iterator()\n",
    "validation_iterator = validation_dataset.make_initializable_iterator()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # input 소스를 선택할 수 있는 핸들러\n",
    "    training_handle = sess.run(training_iterator.string_handle())\n",
    "    validation_handle = sess.run(validation_iterator.string_handle())\n",
    "    \n",
    "    while True:\n",
    "        for _ in range(200):\n",
    "            print('train ', sess.run(next_element, feed_dict={handle: training_handle}))\n",
    "\n",
    "        sess.run(validation_iterator.initializer)\n",
    "        for _ in range(5):\n",
    "            print('valid ', sess.run(next_element, feed_dict={handle: validation_handle}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(3)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "result = tf.add(next_element, next_element)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "   \n",
    "    # 일반적으로 train loop에 사용하는 try-except 블록\n",
    "    try:\n",
    "        print(sess.run(result)) # 0\n",
    "        print(sess.run(result)) # 1\n",
    "        print(sess.run(result)) # 2\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('End of dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices(['A', 'B', 'C'])\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices(([1, 2, 3], ['A1', 'B1', 'C1']))\n",
    "dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "\n",
    "iterator = dataset3.make_initializable_iterator()\n",
    "next1, (next2, next3) = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "    print(sess.run((next1, (next2, next3))))\n",
    "    # iterator에 묶여 있어서 동시에 다음 element로 넘어간다.\n",
    "    print(sess.run(next1)) \n",
    "    print(sess.run((next1, (next2, next3))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Reading input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Consuming NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "y = np.array([0, 1])\n",
    "\n",
    "np.savez('./array', features=x, labels=y)\n",
    "data = np.load('array.npz')\n",
    "\n",
    "features = data['features']\n",
    "labels = data['labels']\n",
    "\n",
    "# The length of features and labels should be the same.\n",
    "assert features.shape[0] == labels.shape[0]\n",
    "\n",
    "feature_placeholder = tf.placeholder(features.dtype, features.shape)\n",
    "labels_placeholder = tf.placeholder(labels.dtype, labels.shape)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((feature_placeholder, labels_placeholder))\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer, feed_dict={feature_placeholder: features, labels_placeholder: labels})\n",
    "    print(sess.run(next_element))\n",
    "    print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Consuming TFRecord data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Consuming text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Preprocessing data with Dataset.map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Parsing tf.Example protocol buffer messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Decoding image data and resizing it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Applying arbitrary Python logic with tf.py_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Batching dataset elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Simple batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inc_dataset = tf.data.Dataset.range(100)\n",
    "dec_dataset = tf.data.Dataset.range(0, -100, -1)\n",
    "dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))\n",
    "# basch 사이즈 지정\n",
    "\n",
    "batched_dataset = dataset.batch(4)\n",
    "\n",
    "iterator = batched_dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(next_element))  # ==> ([0, 1, 2,   3],   [ 0, -1,  -2,  -3])\n",
    "    print(sess.run(next_element))  # ==> ([4, 5, 6,   7],   [-4, -5,  -6,  -7])\n",
    "    print(sess.run(next_element))  # ==> ([8, 9, 10, 11],   [-8, -9, -10, -11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Batching tensors with padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
