{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상수를 더하기 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ab': (3.0, 4.0), 'total': 7.0} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(3.0, dtype=tf.float32)\n",
    "b = tf.constant(4.0)\n",
    "\n",
    "total = a + b\n",
    "\n",
    "# tensorboard를 위해 그래프 추가\n",
    "# 그래프가 완성된 뒤 추가 되어야 한다.\n",
    "writer = tf.summary.FileWriter('./log', tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run({'ab':(a, b), 'total':total}), '\\n')\n",
    "    \n",
    "# print(tf.get_default_graph().as_graph_def())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorboard\n",
    "\n",
    "* 포트를 특별히 지정하지 않으면, 디폴트 포트는 6006이다.\n",
    "* tensorboard의 실행 방법은 다음과 같다.\n",
    "\n",
    "```\n",
    "$ tensorboard --logdir=<path> --port=6006\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.constant(value, dtype=None, shape=None, name='Const', verify_shape=False)\n",
    "\n",
    "# constant of 1d tensor (vector)\n",
    "a = tf.constant([2, 2], name='vector')\n",
    "\n",
    "# constant of 2x2 tensor (matrix)\n",
    "b = tf.constant([[0,1], [2, 3]], name='matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같이 shape을 지정해서 텐서를 생성한 후, 값을 채울 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프의 동작 방식을 이해하기 위한 예제이다. 다음은 그래프가 3번 실행 된다.\n",
    "마지막 실행에서 out1, out2가 동일한 vec값을 사용했다는 점을 확인하기 바란다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec: [0.38927257 0.6899679  0.95704126]\n",
      "vec: [0.01239777 0.34314167 0.63663936]\n",
      "out: (array([1.8807906, 1.1670644, 1.1419008], dtype=float32), array([2.8807907, 2.1670644, 2.1419008], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "#변수 3개 반환\n",
    "vec = tf.random_uniform(shape=(3,))\n",
    "out1 = vec + 1\n",
    "out2 = vec + 2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('vec: {}'.format(sess.run(vec)))\n",
    "    print('vec: {}'.format(sess.run(vec)))\n",
    "    # out1, out2가 동일한 vec을 사용했다\n",
    "    print('out: {}'.format(sess.run((out1, out2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 값을 넣기 위해 placeholder를 추가한 내용이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "z = x + y\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(z, feed_dict={x: 3, y: 4.5}))\n",
    "    print(sess.run(z, feed_dict={x: [1, 3], y:[2, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1,2], [3, 4]])\n",
    "b = tf.zeros([2, 3])\n",
    "c = tf.ones([2, 3])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(a))\n",
    "    print(sess.run(b))\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "* 앞에서 살펴본 tf.constant는 tensor를 반환하는 하나의 함수이다. 하지만 tf.Variable은 여러게의 함수로 구성된 클래스다. (여기 정리해야 함. op, 함수)\n",
    "\n",
    "* tf.Variable 쓰지 말고 tf.get_variable을 사용하도록 한다.\n",
    "* tf.constant는 그래프에 상수화되어 저장되지만 Variable은 parameter server에 메모리 상에 저장된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders\n",
    "\n",
    "* feed_dict를 사용해 입력 값을 지정하던 방식은 지양하는 것이 좋다.\n",
    "* 뒤에 설명할 tf.data.Dataset을 이용하는 방법이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feed_dict을 이용한 디버깅 기법\n",
    "constant, variable 모두 feedable object로 임의의 값을 지정하여 수식을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 3\n",
    "features = 2\n",
    "n_hiden = 3\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[batch_size, features], name='batch_input')\n",
    "\n",
    "w = tf.get_variable(name='weights', dtype=tf.float32, shape=(features, n_hiden))\n",
    "b = tf.get_variable(name='bias', dtype=tf.float32, shape=(1, n_hiden))\n",
    "\n",
    "m = tf.matmul(x, w)\n",
    "result = tf.add(m, b)\n",
    "\n",
    "tf.summary.FileWriter('./log', tf.get_default_graph())\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    feed_dict = {\n",
    "        x: [[1, 2],\n",
    "            [3, 4],\n",
    "            [5, 6]],\n",
    "\n",
    "        w: [[1, 2, 3],\n",
    "            [3, 4, 5]],\n",
    "\n",
    "        b: [[10, 10, 10]]\n",
    "    }\n",
    "\n",
    "    print(sess.run([m], feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Dataset\n",
    "tensorflow 라이브러리 외부에서 데이터를 가공하여 placeholder에 feed_dict를 이용해서 직접 데이터를 넣어 주는 방식보다 좋은 성능을 가지고 있다.\n",
    "\n",
    "Dataset을 이용한 입력 소스 지정 방법을 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = np.array([\n",
    "    [0, 1],\n",
    "    [2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7],\n",
    "])\n",
    "\n",
    "slices = tf.data.Dataset.from_tensor_slices(source)\n",
    "# 초기화 필요 없다.\n",
    "iterator = slices.make_one_shot_iterator()\n",
    "next_item = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    idx = 0\n",
    "    while True:\n",
    "        try:\n",
    "            idx += 1\n",
    "            print(f'{idx}: ',sess.run(next_item))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source = tf.random_normal(shape=[10, 3])\n",
    "slices = tf.data.Dataset.from_tensor_slices(source)\n",
    "# 초기화 필요. (뒤에서 추가 설명)\n",
    "iterator = slices.make_initializable_iterator()\n",
    "next_row = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "    \n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            i+=1\n",
    "            print(i, sess.run(next_row))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = tf.random_uniform([4, 10], minval=0, maxval=100)\n",
    "# 입력 소스로 부터 dataset을 구성\n",
    "dataset1 = tf.data.Dataset.from_tensor_slices(source)\n",
    "\n",
    "print(dataset1.output_types)\n",
    "print(dataset1.output_shapes)\n",
    "\n",
    "inputs = tf.random_uniform([4, 100])\n",
    "labels = tf.random_uniform([4])\n",
    "\n",
    "# 다른 입력 소스를 묶어서 dataset을 구성\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
    "\n",
    "print(dataset2.output_types)\n",
    "print(dataset2.output_shapes)\n",
    "\n",
    "# dataset을 묶어서 새로운 dataset을 구성\n",
    "dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "\n",
    "print(dataset3.output_types)\n",
    "print(dataset3.output_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딕셔너리를 이용한 입력소스 지정 방법. key에 이름을 부여할 수 있음\n",
    "sources = dict()\n",
    "\n",
    "sources['a'] = tf.random_uniform([4])\n",
    "sources['b'] = tf.random_uniform([4, 100])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(sources)\n",
    "\n",
    "print(dataset.output_types)\n",
    "print(dataset.output_shapes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterator 사용 시,range 체크를 반드시 해주는 것이 좋다.\n",
    "\n",
    "```\n",
    "try:\n",
    "    do something\n",
    "except tf.errors.OutOfRangeError:\n",
    "    break\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. one-shot iterator\n",
    "* initialization이 필요 없다. (할 수 없다)\n",
    "* 끝에 도착하면 다시 재활용할 수 없다. 결국, epoch마다 사용 불가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:  \n",
    "          print(sess.run(next_element))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. initalizable iterator\n",
    "* 사용전, initialization 필수\n",
    "* epoch마다 재 활용할 수 있다.\n",
    "* tf.placeholder를 이용해서 동작을 지정할 있는 장점이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = tf.placeholder(tf.int64, shape=[])\n",
    "dataset = tf.data.Dataset.range(max_value)\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    for epoch in range(2):\n",
    "        sess.run(iterator.initializer, feed_dict={max_value: 20})\n",
    "        while True:\n",
    "            try:\n",
    "                print(f'epoch {epoch}: ', sess.run(next_element))\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "            \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. reinitilizable iterator\n",
    "* 여러 Data source로 부터 데이터를 가지고 올수 있다. 단, structure은 동일해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.range(10).map(lambda x: x + tf.random_uniform([], -10, 10, tf.int64))\n",
    "validation_dataset = tf.data.Dataset.range(5)\n",
    "\n",
    "# reinitializable iterator의 경우는 structure로 정의된다.\n",
    "# 다른 Data source라 할지라도 같은 데이터 형태를 가지기 때문에 둘 중 하나를 사용하면 된다.\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types, training_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "validation_init_op = iterator.make_initializer(validation_dataset)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    #The number of epochs\n",
    "    for e in range(20):\n",
    "        print(f'> epoch {e}')\n",
    "        \n",
    "        # train sequence가 초기화 된다.\n",
    "        sess.run(training_init_op)\n",
    "        for _ in range(10):\n",
    "            print(f'train: {sess.run(next_element)}')\n",
    "        # validation sequence가 초기화 된다.\n",
    "        sess.run(validation_init_op)\n",
    "        for _ in range(5):\n",
    "            print(f'valid: {sess.run(next_element)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. feedable iterator\n",
    "* reinitializable iterator와 동일 기능 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat함수를 이용해서 반복되는 sequence를 생성할 수 있다.\n",
    "# repeat함수를 사용하지 않으면 범위를 벗어날 경우, OutOfRangeError가 발생한다.\n",
    "training_dataset = tf.data.Dataset.range(10).repeat()\n",
    "validation_dataset = tf.data.Dataset.range(5)\n",
    "\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(handle, \n",
    "                                               validation_dataset.output_types, \n",
    "                                               validation_dataset.output_shapes)\n",
    "\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "training_iterator = training_dataset.make_one_shot_iterator()\n",
    "validation_iterator = validation_dataset.make_initializable_iterator()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # input 소스를 선택할 수 있는 핸들러\n",
    "    training_handle = sess.run(training_iterator.string_handle())\n",
    "    validation_handle = sess.run(validation_iterator.string_handle())\n",
    "    \n",
    "    while True:\n",
    "        for _ in range(200):\n",
    "            print('train ', sess.run(next_element, feed_dict={handle: training_handle}))\n",
    "\n",
    "        sess.run(validation_iterator.initializer)\n",
    "        for _ in range(5):\n",
    "            print('valid ', sess.run(next_element, feed_dict={handle: validation_handle}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(3)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "result = tf.add(next_element, next_element)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "   \n",
    "    # 일반적으로 train loop에 사용하는 try-except 블록\n",
    "    try:\n",
    "        print(sess.run(result)) # 0\n",
    "        print(sess.run(result)) # 1\n",
    "        print(sess.run(result)) # 2\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('End of dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices(['A', 'B', 'C'])\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices(([1, 2, 3], ['A1', 'B1', 'C1']))\n",
    "dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "\n",
    "iterator = dataset3.make_initializable_iterator()\n",
    "next1, (next2, next3) = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "    print(sess.run((next1, (next2, next3))))\n",
    "    # iterator에 묶여 있어서 동시에 다음 element로 넘어간다.\n",
    "    print(sess.run(next1)) \n",
    "    print(sess.run((next1, (next2, next3))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Reading input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Consuming NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "y = np.array([0, 1])\n",
    "\n",
    "np.savez('./array', features=x, labels=y)\n",
    "data = np.load('array.npz')\n",
    "\n",
    "features = data['features']\n",
    "labels = data['labels']\n",
    "\n",
    "# The length of features and labels should be the same.\n",
    "assert features.shape[0] == labels.shape[0]\n",
    "\n",
    "feature_placeholder = tf.placeholder(features.dtype, features.shape)\n",
    "labels_placeholder = tf.placeholder(labels.dtype, labels.shape)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((feature_placeholder, labels_placeholder))\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer, feed_dict={feature_placeholder: features, labels_placeholder: labels})\n",
    "    print(sess.run(next_element))\n",
    "    print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Consuming TFRecord data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Consuming text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Preprocessing data with Dataset.map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Parsing tf.Example protocol buffer messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Decoding image data and resizing it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Applying arbitrary Python logic with tf.py_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Batching dataset elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Simple batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inc_dataset = tf.data.Dataset.range(100)\n",
    "dec_dataset = tf.data.Dataset.range(0, -100, -1)\n",
    "dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))\n",
    "# basch 사이즈 지정\n",
    "\n",
    "batched_dataset = dataset.batch(4)\n",
    "\n",
    "iterator = batched_dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(next_element))  # ==> ([0, 1, 2,   3],   [ 0, -1,  -2,  -3])\n",
    "    print(sess.run(next_element))  # ==> ([4, 5, 6,   7],   [-4, -5,  -6,  -7])\n",
    "    print(sess.run(next_element))  # ==> ([8, 9, 10, 11],   [-8, -9, -10, -11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Batching tensors with padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
